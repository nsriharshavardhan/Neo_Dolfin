# -*- coding: utf-8 -*-
"""DolFin Transaction Classification_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16DF4U_g-7FyBkk1kA5DnvAg7diiSBEAQ

# DolFin Transaction Classification
This notebook is for training and testing a DolFin NLP model that will classify the transactions based on their description, the model has been developed with the intention of replacing the existing Basiq API which has provided poor classification results. The first part of this notebook is data wrangling and preparing the classes and tokenising the transaction descriptions.In the second past we have implemented the LSTM model for multiclass classification on the fake transactions data.

Code by Samruddhi Bhor
"""

pip install tensorflow pandas nltk wordcloud

# Processing Utilities
import datetime
import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder

# Natural Language Processing
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')
nltk.download('stopwords')

# Deep learning
import tensorflow as tf
from tensorflow import keras
from keras import Model, layers

# Plotting utillities
import matplotlib.pyplot as plt
import seaborn as sns

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Data location, batch and image size
dataset_dir = '/content/drive/MyDrive/Colab Notebooks/Projects/'
# file_name = 'transaction_ut.csv'
file_name = 'fake_bank_account_transactions.csv'

# Load the dataset into a dataframe
df = pd.read_csv(dataset_dir + file_name)

# Shuffle the dataframe
df = df.sample(frac=1).reset_index(drop=True)

# Store the column names
labels = list(df.columns)

# Determine the shape of the data
num_samples = df.shape[0]
num_features = df.shape[1]

msg = f'The file {file_name} contains {num_features} features and {num_samples} samples \n'
msg += f'The column names are: {labels}'
print(msg)

# Display the datatypes for each of the features
df.dtypes

df.head(10)

df['Category 2'].value_counts()

df['Description'].value_counts()

# Rename the column from "Category 3" to "class"
df.rename(columns={'Category 3': 'class'}, inplace=True)

#
df['class'].unique()

# Create a stop words variable
stop_words = set(stopwords.words('english'))

# Preprocess the text in the content field
def preprocess_content(text):
    # Covert the text to lower case
    tokens = word_tokenize(text.lower())
    # Remove stop words from the text and ensure each token is seproate by a space
    result = ' '.join([word for word in tokens if word.isalpha() and word not in stop_words])
    return result

# Apply the preprocessing transformation
df['processed_text'] = df['Description'].apply(preprocess_content)

# Tokenisation of the processed_text
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(df['Description'])
sequences = tokenizer.texts_to_sequences(df['Description'])
padded_sequences = pad_sequences(sequences, maxlen=200)

# Mapping sentiments to integers
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(df['class'])
labels = to_categorical(integer_encoded)

# Specify the split into train, test, split
train_split = 0.6
test_split = 0.2
val_split = 0.2

# Determine the number of samples
train_samples = int(train_split * num_samples)
test_samples = int(test_split * num_samples)
val_samples = num_samples - test_samples - train_samples

x_train, x_temp, y_train, y_temp = train_test_split(padded_sequences, labels, test_size=0.3, random_state=42)
x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)

# Create a tensorboard callback
log_dir = os.path.join("logs", "fit", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

# Create a early stopping callback to prevent overfitting
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, verbose=1)

tf_callbacks = [tensorboard_callback, early_stopping]



num_classes = labels.shape[1]

# Develop the model
nlp_model = tf.keras.Sequential([
    layers.Embedding(5000, 16, input_length=200),
    layers.Bidirectional(layers.LSTM(64)),
    layers.Dropout(0.2),
    layers.Dense(6, activation='relu', kernel_initializer='he_uniform'),
    layers.Dense(num_classes, activation = 'softmax')
])

nlp_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

nlp_model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs

# Specify the maximum number of epochs
num_epochs=100
batch_size = 32

# Fit the model to the training data
history = nlp_model.fit(x_train, y_train, epochs=num_epochs, batch_size=32, validation_data=(x_val, y_val), callbacks=tf_callbacks)

# Save a copy of the model
nlp_model.save_weights('nlp_model.h5')

# Create a function to display the training accuracy and loss
def plt_accuracy_loss(history):
    # Plot the training history
    accuracy = history.history['accuracy']
    loss = history.history['loss']
    epochs = range(len(accuracy))

    figure, ax = plt.subplots(2, 1, figsize=(12, 8))

    colors = sns.color_palette("crest", n_colors=2)

    ax[0].plot(epochs, accuracy, '-o', color=colors[0])
    ax[0].set_title('Training Accuracy')
    ax[0].set_xlabel('Epochs')
    ax[0].set_ylabel('Accuracy [%]')

    ax[1].plot(epochs, loss, '-o', color=colors[1])
    ax[1].set_title('Training Loss')
    ax[1].set_xlabel('Epochs')
    ax[1].set_ylabel('Loss [%]')

    plt.tight_layout()
    plt.show()

plt_accuracy_loss(history)

# Calculate the model accuracy
loss, accuracy = nlp_model.evaluate(x_test, y_test)
print(f'Test Accuracy is {accuracy:.2f}')

"""1. Use hyper parameterisation to identify better combinations of dropout and dense layer configurations.
2. Setup tensorflow to log the score for each hyperparameter combination.
3. Generate code that will save the best performing model from the validation score.
"""

# Import necessary callbacks
num_epochs = 100
from tensorflow.keras.callbacks import ModelCheckpoint

# Define a ModelCheckpoint callback to save the best model based on validation loss
checkpoint_callback = ModelCheckpoint('best_model.h5',
                                      monitor='val_loss',
                                      verbose=1,
                                      save_best_only=True,
                                      mode='min')

# Modify tf_callbacks list to include ModelCheckpoint
tf_callbacks = [tensorboard_callback, early_stopping, checkpoint_callback]

# For hyperparameterization, we will use grid search or random search
# Define a grid of hyperparameters
dropout_rates = [0.2, 0.3, 0.4]
dense_layer_sizes = [32, 64, 128]

best_val_score = float('inf')  # Initialize with a large value
best_model_params = {}

# Iterate over all combinations of hyperparameters
for dropout_rate in dropout_rates:
    for dense_layer_size in dense_layer_sizes:
        # Build model with current hyperparameters
        model = tf.keras.Sequential([
            layers.Embedding(5000, 16, input_length=200),
            layers.Bidirectional(layers.LSTM(64)),
            layers.Dropout(dropout_rate),
            layers.Dense(dense_layer_size, activation='relu', kernel_initializer='he_uniform'),
            layers.Dense(num_classes, activation='softmax')
        ])
        # Compile the model
        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

        # Train the model
        history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=32,
                            validation_data=(x_val, y_val), callbacks=tf_callbacks)

        # Get the best validation score
        val_loss = min(history.history['val_loss'])

        # Check if this model has a better validation score than the current best
        if val_loss < best_val_score:
            best_val_score = val_loss
            best_model_params = {'dropout_rate': dropout_rate, 'dense_layer_size': dense_layer_size}
            # Save the model
            model.save('best_model.h5')

print("Best validation score:", best_val_score)
print("Best model parameters:", best_model_params)

"""## Observations

* The model's training accuracy increases with each epoch, indicating that it is learning from the training data.
* The model's validation accuracy also increases, but it may fluctuate or plateau after a certain number of epochs.
* The loss decreases over epochs, indicating that the model's predictions are improving over time.
* The best validation score achieved during training is 0.16838, and it corresponds to the model trained with a dropout rate of 0.3 and a dense layer size of 64.
"""

# Load the best model
best_model = tf.keras.models.load_model('best_model.h5')

# Evaluate the best model on test data
test_loss, test_accuracy = best_model.evaluate(x_test, y_test)

print(f"Test Accuracy of the best model: {test_accuracy}")

"""### The Test accuracy for best model is 98% which seems as a good model"""