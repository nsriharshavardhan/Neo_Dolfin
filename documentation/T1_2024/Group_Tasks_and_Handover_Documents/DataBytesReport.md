

**DataBytes - Company Structure and Objectives
for 2024, Trimester 1**

**Executive Summary**

DataBytes is a multi-disciplinary company that researches data-driven
solutions and creates platforms and applications. We work with
cutting-edge technology in the fields of artificial intelligence, data
science and digital finance to develop solutions that will have a
positive global impact.

Our teams cover a variety of sectors including environmental
sustainability, personalised education, online advertising, fintech,
open banking, consumer data rights, data portability, retail,
e-commerce, and online payments. Our teams work on a variety of sectors
including environmental sustainability, personalised education, online
advertising, fintech, open banking, consumer data rights, data
portability, retail, e-commerce, and online payments. We have an
excellent track record for inventing innovative applications that
leverage AI processing technologies.

Databytes current projects include:

1.  **DolFin** - An innovative financial wellness platform that
    integrates open banking data and utilizes advanced Artificial
    Intelligence (AI) and Machine Learning (ML) technologies to optimize
    financial management.

2.  **Project Echo** - Audio processing software that uses AI models to
    spot endangered species in the Otways, underlining our dedication to
    environmental preservation.

3.  **Privacy Technology for Financial Intelligence (PTFI)** - Aims to
    combat financial crime using advanced privacy technologies to
    safeguard personal information while facilitating secure data
    sharing for intelligence purposes.

4.  **DiscountMate** - A recently reactivated effort to empower
    consumers by providing reliable information on discounted products
    across various supermarket chains, improving the shopping experience
    and lowering the cost of living.

# Contents 

[**DataBytes - Company Structure and Objectives for 2024, Trimester 1**](#_Toc164601349)

[**Executive Summary**](#_Toc164601350)

[**Leadership Team** ](#_Toc164601351)

[**Trimester Goals and Objectives**](#_Toc164601352)

[**Company Structure and Projects Overview**](#_Toc164601353)

[**Project 1 DolFin**](#_Toc164601354)

**Leadership Team**

The following diagram demonstrates an outline of our company\'s
organizational chart, structured around our primary product lines.
Leading each product line is a team of our senior student leaders, who
together constitute the \'company board\'. In our DataBytes community,
we adhere to a flat organisational model. All other student participants
work under the guidance of this company board.

!! Issue with media upload, will need to be done separately.
![](media/image2.svg){width="6.263888888888889in"
height="4.538194444444445in"}

**Trimester Goals and Objectives**

1.  **Project Progress and Documentation**: Achieve all sprint goals and
    deliverables for the trimester. This includes progressing the
    product towards its intended destination and improving the handover
    document.

2.  **UI/UX Development**: Continue to develop the UI/UX to meet the
    needs of users and stakeholders.

3.  **MVP Development**: Work towards building a Minimum Viable Product
    (MVP) that encapsulates the core functionality of your product.

4.  **AI Enhancement**: Enhance the AI model and apply it to solve
    real-world problems.

5.  **LinkedIn Page Improvement**: Improve the LinkedIn webpage by
    adding more information about the available products.

Company Structure and Projects Overview**

The DataBytes company has currently 3 projects active and 1 project on
discussion:

Active projects:

-   DolFin

-   Project Echo

-   Privacy Technologies for Financial Intelligence

On Discussion projects:

-   DiscountMate

All projects under the DataBytes utilize a consolidated workspace on
platforms like [Trello](https://trello.com/w/databytesorganisation) and
[GitHub](https://github.com/DataBytes-Organisation). This approach
centralizes task management and software outcomes, fostering a
collective identity among team members.

Members of the DataBytes team are integrated into our broader
organization and can contribute to any active projects. Each team member
is primarily affiliated with a specific project, but they may also
contribute to other projects as needed. This primary project serves as
the focal point for each member throughout the trimester, enabling them
to make significant and lasting contributions. This structure promotes
efficiency and a sense of shared purpose within the team.

**Project 1 DolFin**

**Overview, Goals, and Objectives**

DolFin is an innovative financial well-being platform that integrates
open banking data and leverages cutting-edge artificial intelligence
(AI) and machine learning (ML) technologies to streamline financial
management, offer personalized forecasts and advice, and deliver these
insights through a smart chatbot interface.

At the heart of the DolFin project is the ambition to overcome the
limitations of the traditional banking system, characterized by
monopolistic behaviours and unequal service provision to different
demographics. By offering an open, accessible platform, DolFin aims to
enable effective financial management for everyone, regardless of their
economic status.

The long-term goals of the DolFin project extend beyond immediate
financial management aid. It aims to foster financial literacy,
encourage healthy financial habits, and ultimately contribute to
reducing the economic inequality gap. By empowering users with knowledge
and tools to make informed financial decisions, DolFin intends to create
a more inclusive financial ecosystem that benefits everyone, not just
those who can afford traditional advisory services.

The stakeholders of the DolFin project include Deakin Capstone students,
who are integral to its development and implementation; the company
director, who oversees the strategic direction of the project; Deakin
staff, who provide academic support and guidance; and, most importantly,
individuals seeking to improve their financial well-being. For these
stakeholders, DolFin promises not only to revolutionize the way they
interact with their finances but also to provide them with a platform
that supports their financial growth and resilience.

GitHub: <https://github.com/DataBytes-Organisation/Neo_Dolfin>\
Trello:
<https://trello.com/b/gk0hg39G/major-product-3-dolfin-new-fintech>

**Aims for Trimester**

*Previously*

1.  Conduct market research on DolFin to understand potential
    competitors and analyze their strengths and weaknesses.

2.  Read academic literature related to financial well-being and write a
    report on how it could be applied in DolFin.

3.  Redesign the web interface to make it more relevant to financial
    application.

4.  Refactor the back-end code and use modular programming to make
    development effective.

5.  Open user registration function and password reset function.

6.  Allow users to select specific transaction data as the data source
    (such as within a specific time period).

7.  Optimize prediction-related models and put them into use.

8.  Rebuilding AI Chatbot to make it smarter.

9.  Continue penetration testing.

*Additionally*

10. Create and implement password policies for a more robust security
    posture.

11. Create a framework for application of React instead of current
    front-end framework.

12. Plan for the migration of the current SQLite database to MongoDB.

13. Create and employ the usage of specific and dedicated user profiles
    of our targeted audience for data training.

**Deliverables**

*Trimester Deliverables*

1.  Market research results and related reports on DolFin.

2.  Brand new user-centric web interface.

3.  Robust back-end design and realization.

4.  Interactive dashboard.

5.  Customized smart chatbot.

6.  Define data handling policies for a safer data environment.

*Long-term Deliverables*

1.  Refactor the code and separate the front end, back end and database.

2.  Rewrite the front-end code and use React as a framework to improve
    scalability.

3.  Develop mobile applications.

4.  Redesign the backend using DDD and refactor the code using
    microservice. Architecture.

5.  Deploy the program on the hosting platform.

6.  Design data models using AI to categorise and analyse data given by
    users.

7.  Implement password storage encryption.

**Project Members**

!!Media upload issue. Will need to check what is up with that
![](media/image3.png){width="6.454166666666667in"
height="4.840277777777778in"}

**Contributions by Individual Members**

*Leadership Team*

| Name               | Role            |
|:-------------------|:----------------|
|Denica Hope         | Senior Leadership, DS/AI Stream Lead | 
|Gimsara Elgiriyage  | Senior Leadership, FE Lead           |
|Mariska Heera Mohanadas | Senior Leadership, CS Lead       | 
|Junkai Jiang        | Senior Leadership, BE Lead           |
|Samruddhi Bhor      | DS/AI Stream Co-Lead, Code Review Lead | 
|Pradipta Dutta      | FE Stream Co-Lead, Code Review Lead  |

*Squad Members*

| Name               | Stream          |
|:-------------------|:----------------|
|Aishwarya Mahajan   | DS/AI           |
|Amandeep Kaur Sandhu| DS/AI + MR         |
|Armaan Chetal       | FE+MR+DS/AI        |
|Asma Alsheddi       | FE + BE         |
|Ata Colak           | DS/AI           |
|Axesh Patel         | DS/AI           |
|Ben Bradhurst       | FE+BE+MR           |
|Damion De Motte     |    |
| Darsana Prakash   |DS/AI    |
|Deepak Kumar Khatri |BE + FE + MR|
|Denica Hope |DS/AI + MR + BE|
|Divanshi Divanshi |FE+MR+DS/AI|
|Faysal Bhatti |FE|
|Gia Nguyen Phung |DS/AI|
|Gimsara Elgiriyage |FE|
|Gunjan Sharma |FE+MR+DS/AI|
|Hassaan Syed |CS|
|Heera Mohanadas |CS|
|Imran Mughal |CS|
|Jack Genesin |DS/AI|
|Jensen Tang |DS/AI|
|Junkai Jiang |BE + MR|
|Krish |FE+ DS + MR|
|Liny Jose Alias| DS/AI|
|Muhammad Saad Ali |CS+FE|
|Muhammad Saad Saad |CS + FE|
|Nick Lane| DS/AI|
|Pradipta Dutta |DS/AI + MR|
|Ricky Boeing |BE + FE + DS/AI|
|Sagar Gupta |BE + FE + DS/AI|
|Sahana Gollapalli |DS/AI|
|Samruddhi Bhor |DS/AI|
|Sri Harsha Vardhan  Nimmalapudi |DS/AI + MR|
|Sushant Dudeja |FE+MR+DS/AI|
|Tingting Lu |FE + MR|
|Vicky Kumar |FE+MR+DS/AI|
|Vishal Kumar |FE + MR + BE|
|Yeni Waliatin |FE, CS, DS/AI|
|Yi Guan |FE+BE|
|Zakarya Guerinat |FE|


------------------------------------------------------------------------

**Contribution Updates**

**Week 6 Overall Progress**

*Trimester Deliverables:*

1.  **Market research results and related reports on DolFin**

    a.  Market research results have been shared and utilised to plan
        the development and future of the project

2.  **Brand new user-centric web interface**

    a.  Web interface is still a work in progress, with Figma designs
        having been generated for various pages

3.  **Robust back-end design and realisation**

    a.  Over half of the back-end routes have been rebuilt and optmised

4.  **Interactive dashboard**

5.  **Customised smart chatbot**

    a.  Chatbot responses and learning have been optimised

6.  **Define data handling policies for a safer data environment**

    a.  Data handling policies have been developed

7. **Create Transaction Classification AI model**

    a. Multiple NLP models have been developed to replace the Basiq API for next trimester.

8. **Create a Fraud Detection AI model**

    a. A fraud detection model has been developed to protect DolFin customers.


**New:**

7.  **Define and implement password management policies for a more
    robust security posture**

    a.  Password policies were developed with regard to industry best
        practices and well-regarded frameworks. They have been employed
        to advise feature creation and development of DolFin's security
        posture with external and internal stakeholders.

8.  **Research best practices for password encryption**

9.  **Design a framework for the front end to utilise React in the
    future instead of merely CSS and Html**

10. **Design a framework for the current SQLite database to migrate to
    MongoDB**

**Individual Contributions**

<details>

<summary>Sprint 1 and 2 Contributions</summary>

| Name                  | Contributions|
|:-------------|:-------------------|
| Aishwarya Mahajan   |• Python Mastery: Enhanced my proficiency with critical Python libraries such as NumPy and Pandas, crucial for data analysis and manipulation tasks. This skill set allows for advanced data processing capabilities within the DolFin project. • Created Python Script for Data Quality: Developed a Python script specifically for data dictionary validations and will be enhancing it further with upcoming data fields. This script ensures that incoming data adheres to established quality standards, significantly enhancing data integrity and reliability. • Machine Learning Algorithms: Invested time to understand and implement machine learning algorithms, building a base for the development of predictive models that can influence financial outcomes and decision-making processes. • Data Validation Automation: Script that automates the data validation process for the DolFin project. This tool improves the efficiency and accuracy of data quality checks, streamlining data operations and ensuring compliance with data standards. |
| Amandeep Kaur Sandhu|  <ol type="1"><li>Conducted extensive market research and competitor analysis to identify unique                                                                      opportunities for DolFin, enhancing its competitive edge in the fintech ecosystem.</li><li>implemented advanced data science techniques to enhance the performance of financial transaction classification models.</li><li>Developed alternative visualization methods for model performance to provide intuitive insights for the DolFin team.</li><li> Identified new applications for the model output, adding value to DolFin staff in their day-to day decision-making and strategic planning.</li></ol>   |
| Armaan Chetal |               |
| Asma Alsheddi |               |
| Ata Colak     | Fixed issues in a few queries in the chatbot which causes it to not give a response and sent a PR. Taken the co-lead of the chatbot project. Still working on implementing a more comprehensive chatbot model to DolFin while keeping in close touch with AI stream lead and chatbot co-lead Axesh. |
| Axesh Patel   |<ol type="1"><li>Conducted market research for Dolfin app's financial well-being segment</li><li>Analyzed market trends, user preferences, and competitor offerings</li><li>Prepared a detailed report with findings and recommendations</li><li>Researched and evaluated new Language Models (LLMs) for chatbot enhancement </li><li>Explored various LLMs to identify potential replacements for the existing chatbot</li><li>Selected and implemented LLAMA2 LLM for chatbot replacement</li><li>Chose LLAMA2 as the most promising LLM after careful evaluation</li><li> Developed a basic chatbot prototype using LLAMA2</li><li>Pushed updated chatbot code to project's GitHub repository for version control and collaboration </li><li>Explored Generative Adversarial Networks (GANs) for synthetic transactional data generation</li><li>Researched GANs' application in generating synthetic transactional data </li><li>Implemented a GAN-based solution and experimented with different hyperparameters but didn't got expected outcomes</li><li>Investigated LLAMA.CPP library for enhanced chatbot flexibility </li><li>Explored LLAMA.CPP library to make the chatbot more flexible and customizable</li><li>Encountered unexpected errors in LLAMA.CPP and working on resolving them.</li></ol>|
| Ben Bradhurst |               |
| Damion De Motte | - Getting up to speed with regards to current requirements in the Dolfin project/product - Conducting research on SQLiute and more specifically parameterised queries and how it can be applicable to Dolfin -Pivoting research to MongoDB and how it may be more beneficial due to the decision to opt to use it |
| Darasana Prakash |               |
| Deepak Kumar Khatri | 1. Designed Registeration Page using Figma 2. Worked on market Research Task by working on to Find Market Compititors add reference designs. 3.Created a document outlining the purpose and information required for the registration page. 4. Helped fellow students with the  issues they were facing. 5. Finished Signout Route Task and pull request was approved. 6. Finished Clear Transaction Optimization and sent pull request to Github|
| Denica Hope | <li>Assisted with the onboarding presentation.</li><li>Created Trello cards for Market Research stream</li><li>Conducted Market Research on Financial Wellbeing in Tech Apps and prepared an individual research report.  </li><li>Prepared a consolidated summary of all market research submissions and a powerpoint to present overall findings </li><li>Hosted meetings with Market Research stream to provide clarity on tasks</li><li>Hosted meetings for Data Science/AI streams</li><li>Researched how to generate random financial data </li><li>Created Trello cards for Data Science/AI streams </li><li>Created a randomly generated home loan data set and credit card data set</li><li>Research how to consolidate payment transactions from these datasets into general transaction data set that will also include other randomly generated transactions and transaction classification categories.</li><li>Meet with Product Owner and mentor to discuss product and tasks</li><li>Assist other students with general questions about the unit or specific questions about Trello tasks. </li> |
| Divanshi Divanshi |               |
| Faysal Bhatti |               |
| Gia Nguyen Phung | -Decode tokens to words in transaction classification -Display distribution of classess after importing the dataset|
| Gimsara Elgiriyage |  * Assisted with the onboarding presentation. * Met with the Dolfin Leadership team to discuss the responsibility of leaders, the content of the onboarding presentation, and future schedule* Created Trello cards for Front End stream.* Conducted Market Research on UI of financial wellbeing applications and created a report.* Hosted meetings with the Front End stream to provide clarity on tasks and help peers.* Met with Product Owner and mentor to discuss product and tasks.* Assisted other students with general questions about the unit to help them get onboard with ease or specific questions about Trello tasks.* Came up with new UI/UX features and presented them to Kelvin.* Corrected a broken route in the web app.* Added sign up and login animations.* Started working on a feature to allow users to leave reviews.* Appointed a sub team to work on the conversion of HTML/CSS to React. |
| Gunjan Sharma |               |
| Hassaan Syed  | * Created privacy policy * contributed to report on Global Hashing Pepper|
| Heera Mohanadas | <li>Created data governance policy</li><li>Created password policy </li><li>Created Trello tasks and proposed technical features to the product owner and project mentors </li><li>Created password complexity requirements and coded them into Dolfin's registration page - with an accompanying feature report explaining code</li><li>Assisted with the onboarding presentation and hosted onboarding presentation with other leads for students </li><li>Attended meetings and discussed product and features for security development with Product Owner and Mentors</li><li>Assisted other students with general questions concerning the unit, troubleshooting questions, and aid for Trello Tasks</li><li>Finished the Dolfin section of the 6.1P Company progress report </li><li>Created the base of the markdown to collect student contributions for Sprints   </li>|
| Imran Mughal |               |
| Jack Genesin | Conducted market research on Financial Wellbeing and produced a report highlighting the findings, along with competitor examples - Wrote a Python script for generating randomised Home Loan account datasets. Created 'User C' Home Loan profile and generated a Home Loan account dataset for them -Wrote a Python script for generating randomised Credit Card account datasets. In the process of creating 'User C's Credit Card profile and generating a Credit Card dataset for them - still in the works|
| Jensen Tang |               |
| Junkai Jiang |  <ol type="1"><li>Fix the shadow image issue</li><li>Coordinate week 0 company presentation</li><li>Clean up Trello Board</li><li>Clean up GitHub </li><li>Meet with the Dolfin Leadership team (Discuss the responsibility of leaders, the content of the onboarding presentation, and future schedule) </li><li>Meet with product owner Kelvin Li (Discuss the current situation about Dolfin)</li><li>Apply the budget request of Dolfin</li><li>Set up the market research squad and publish related Trello cards </li><li>Prepare onboarding presentation </li><li>Write a post about how to configure the access token </li><li>Clean up abandoned code </li><li>Rebuild and deploy the DB and API module</li><li> Onboarding presentation (BE part) Publish Trello cards related to BE for week 3</li><li>Coordinate and be responsible for onTrack task2.1 P </li><li> Prepare for the week 3 presentation about how Dolfin works</li><li>Contact the Basiq team for more information </li><li>Reported financial well-being survey prototypeGive a tutorial about how Dolfin run </li><li>Contact Basiq teamOrganise the database structure from the report and submit it to Kelvin Li</li><li>Use React to build the Dolfin_new front-end framework </li><li>Use Flask to build the Dolfin_new back-end framework </li><li>Use nginx as the Dolfin_new webserverUse docker to containerise the Dolfin_new </li><li>Review the pull request for rebuilding the sign-out routeWeekly BE Stream meeting /li><li>Write notes about dolfin_new</li><li>Nominate BE co-leader</li></ol> |
| Krish  |               |
| Liny Jose Alias | 1)Upskilling in Data Wrangling skills. 2)Building Expertise in Machine Learning Model implementation. 3)Learning Data Generation using Python. 4)Currently working on the Data Generation card where a user story is created and Data generated using python based on the User Story. 5)Active participation in Meetings and Team Collaboration |
| Muhammad Ali Saad  |               |
| Muhammad Saad Saad |               |
| Nick Lane |               |
| Pradipta Dutta |               |
| Ricky Boeing |               |
| Sagar Gupta |               |
| Sahana Gollapalli |               |
| Samruddhi Bhor | 1. Conducted hyperparameterization to optimize dropout and dense layer configurations for an NLP model aimed at classifying transactions based on description. 2. Configured TensorFlow to log performance scores for each hyperparameter combination. 3. Developed functionality to automatically save the best performing model based on validation scores. 4. Undertook the leadership role of representing DolFin in weekly Monday meetings, providing comprehensive updates on the progress of all streams within DolFin. 5. Acted as a key reviewer for data and AI-related pull requests on GitHub, ensuring quality and adherence to standards. 6. Collaborated with the DS/AI leader, Denica, to discuss and provide insights on Trello cards, contributing to effective project management and decision-making processes. |
| Sri Harsha Vardhan Nimmalapudi | • Generated individual market research report on market competitor identifying the key components required for a financial well being application. •  Changing the sentiment analysis to multiclass classification. •  Used hyperparameters to identify the better combinations of dropout and dense layers.  • Joined weekly team meetings to volunteer for tasks and update on the progress of work. • Logged the score for each hyperparameter combination and setup tensorflow to display it.  • Written code to save the parameters and the weights of the best performing model. • Decoded tokens to generate sentences of text back from the tokenisation done in the initial phase of the model. • Generated word clouds for 3 different sentiments and made plots to display the distribution of the dataset.  • Implemented BERT model from pretrained BERT tokenizer using bert-base-uncased. • Used the same adam optimizer and categorical crossentropy loss on the model to compare it in a similar environment to the LSTM model.      • Created a pull request with all the changes made to the sentiment analysis model in github. |
| Sushant Dudeja |               |
| Tingting Lu | * Attended meetings with team leaders and mentors to understand tasks need to complete. * Participated squad meetings for the tasks addressed in Trello * Researched front end design trend for financial products  * Completed individual market research report |
| Vicky Kumar |               |
| Vishal Kumar | • Participated in meetings with mentors and team leaders to understand project requirements. • Had communication and interacted with team leaders to address task-related issues or understand specific requirements. • Designed the registration page UI using Figma • Created a document outlining the purpose and information required for the registration page.  • Researched market competitors and identified areas for improvement based on competitor analysis.     • I implemented the registration page using HTML and CSS code. • After implementing the registration page using HTML and CSS, I noticed that it was not responsive enough. Therefore, I made the page responsive as well. |
| Yeni Waliatin |               |
| Yi Guan       |               |
| Zakarya Guerinat     |               |

</details>

<details>

<summary>Sprint 3&4 Contributions</summary>

| Name                  | Contributions|
|:-------------|:-------------------|
| Nicholas Lane   | Write contributions here ! <li>I developed a NLP model that uses transfer learning to classify transactions using a BERT transformer.</li><li>I wrote code to clean and preprocess text data, encode class labels, then tokenized transaction descriptions using BERT tokenizer, convert to BERT input format.</<li><li>Created a function to create datasets, create datasets for training, validation, and testing.</li><li>Loaded in the Pre-trained BERT Model: Load pre-trained BERT model for NLP classification, then added an output layer for class prediction.</li><li>Compiled and train the BERT model with training dataset and fine tuned the model and finally evaluated the performance of the model.</li><li>Updated the code to include the DolFin colour code format, and resubmitted the code</li><li>I development of a Deep Neural Network model to identify and classify fraudulent bank transactions.</li><li>I searched for a suitable dataset, that would contain the information that DolFin would be able to access through the Open Banking platform.</li><li>I write code to clean and preprocess the various data types and prepare them for the deep learning model.</li><li>I split the data into training and testing datasets which were then made into TensorFlow datasets, which had been shuffled and prefetched.</li><li>I developed a model and added regulation to improve the model’s generalizability and reduce overfitting to the training data.</li><li>>The model was compiled and then evaluated, I also updated the colours to the Dolfin colour format and then submitted the code as a .py file.</li><liAttended product owner meetings and team meetings</li><li>Assist with handover documentation and presentation slides.</li>|
| Junkai Jiang | Write notes about how to set up Dolfin_new<br/>Set up Dolfin_new GitHub repository<br/>Develop JWT service for user authentication(Dolfin_new)<br/>Develop Basiq API service(Dolfin_new)<br/>Develop database service(Dolfin_new)<br/>Review the pull request by Deepak: Optimization of the clear transaction function.<br/>Review the pull request by Sagar: Email verification function.<br/>Review the pull request for rebuilding the login route and update the login page<br/>Review the pull request for rebuilding the dashboard<br/>Set up Dolfin_new Trello backlog<br/>Redesigned and developed the dashboard web interface of the new project<br/>Discussions with Junior Developer<br/>Discuss with Junior about setting up a Dolfin account<br/>Discuss with Junior about the transition of the project (React part)<br/>Discuss with Junior about the account delete functionality<br/>Discuss with Juniors about the handover document<br/>Connect the reported financial well-being feature to the database and backend(Dolfin_new)<br/>Connect income and expenditure overview to the backend(Dolfin_new)<br/>Connect D-cloud to the backend(Dolfin_new)<br/>Add linking to the bank account feature(Dolfin_new)<br/>Fix the backend Docker file<br/>Complete the showcase video (Dolfin_new part) |
| Ata Colak |<li>Develop chatbot which uses Groq API as inference engine and LLAMA3-70b as large language model</li><li>Experiment running LLMs locally. Best performing model locally is "Phi3" using "Ollama".</li><li>Introduce logic to pass LLMs only relevant transaction info, reducing risk of hallucination tremendously.</li><li>Introduce capabilities to store different files correlating to different dates</li><li>Got PR merged for the final state of chatbot which extracts date information from user message, searches KnowledgeBase folder for relevant date, and answers user question related to their transactions.</li>
| Axesh Patel |<li>Solved all the errors and fine-tuned the Llama.cpp model and successfully pushed the code on GitHub.</li><li>Created Dolfin comprehensive FAQ document containing 100 general questions and answers related to customer assistance for the Dolfin application.</li><li>Integrated the FAQ document as a knowledge base for the chatbot, utilizing a Retrieval-Augmented Generation (RAG) model for accurate responses.</li><li>Implemented a new version of the chatbot using Groq cloud's API to leverage Meta's latest LLAMA3 model.</li><li>Enhanced chatbot capabilities by utilizing the newest version of the LLM, improving performance and user interaction.</li><li>Created a detailed report comparing the LLAMA CPP model and the LLAMA Groq API model.</li><li>Added voice recognition and sentiment analysis features to both Llama.cpp and Groq API versions of chatbots.</li><li>Integrated both chatbot models with the front end, providing flexibility to switch between models by simply commenting/uncommenting code.</li><li>Documented the implementation and integration process for both chatbot models, detailing steps.</li>
| Deepak Kumar Khatri| <li>Worked on Login Route to change it to Login Using Email Rather Than username</li><li>Updated Login User interface </li><li> Helped Aishwarya with Github commits and Data Quality Scripts </li><li> Helped Sahana Setting up the Code Enviroment, Gave her overview of the Code</li><li>Helped Sahana With Profile Route Updation and helped her to commit the Code on Github </li><li>helped Vishal with his Delete user Account task by providing code guidance</li><li>Helped Liny with setting up the code Enviroment and helping her to understand the Code.</li><li>Set up the New Dolfin on my local system</li><li>Currently Working on Writting Code Setup instruction</li><li>Attended HandOver Document Meeting to understand the process, will start work on it</li> 
| Vishal Kumar | <li>Implemented registration page functionality, ensuring responsiveness after addressing non-responsiveness issues.</li><li>Worked on the implementation of the "Delete an Account" feature, advancing both front-end and back-end tasks.</li><li>Collaborated with Junkai to enhance understanding of backend systems, databases, and routes for effective execution of the task.</li><li>Successfully completed the frontend and backend task for the "Delete an Account" functionality.</li><li>Encountered a testing issue due to the absence of data in the new database; identified the root cause and discussed it with team members for resolution.</li><li>Completed the data insertion process for the new database, enabling proper testing of the "Delete an Account" functionality.</li><li>Tested and ensured the functionality of the "Delete an Account" feature; committed and merged the code into the development branch after review.</li><li>Discussed and planned the next task with team members: adding an Acknowledgment Section to the About Us page.</li><li>Implemented the Acknowledgment Section in the About Us page, with the code committed and approved after review.</li> |
| Aishwarya Mahajan | <li> Proposed and established a comprehensive data quality platform by sharing a data quality report.</li><li> Created validation scripts for data dictionary ensuring data integrity and accuracy for customer, account, transaction and loan tables.</li><li> Implemented checks for not-null constraints, unique constraints, range validations, allowed values, and regex pattern matching.</li><li> Introduced a new Data Quality folder in the GitHub repository.</li><li> Formed and led a dedicated Data Quality team focussing the validation of transactional data in database.</li><li> Developed Python scripts for visualizing monthly spending data for users.</li><li> Created detailed bar charts with color gradients to indicate spending intensity. </li> |
| (Mariska) Heera Mohanadas | <li> Reviewed logging function, created report / review on it.</li> <li> Enhanced logging function, adding log rotation and reduced noise</li> <li> Created internal denial list to reject common/weak strings in potential passwords</li> <li>Conducted risk assessments on two third-party services, GroqCloud API and Pinecone</li> <li>Attended leadership meetings to discuss handover documents, and discuss project future</li> <li> Created script for Dolfin (old) showcase video, recorded my part and then added Junkai's part into it, and then uploaded showcase video to Panopto</li> <li>Reviewed the work of other students (code and documentation) to ensure they satisfied corresponding requirements of their Trello task, primarily cyber security students though</li> <li>Answered student queries</li> <li>Regularly posted updates and notified Dolfin project members on the timelines of the unit</li> <li>Answered student queries, troubleshooting</li> <li>Conducted code reviews on PRs, ensuring they do not adversely affect or compromise the security of the website or its credentials</li> <li>Hosted a meeting to discuss handover documents and delegation with junior leadership students</li>|
| Denica Hope | <li> Finalised the creation of the data generation python scripts for transaction data, home loan data, credit card data including compiling a reference list of hundred Australian merchant names (real businesses) that I also categorised with our new classfication categories </li> <li> Created a python script to replicate item 3 of the Melbourne Institute-CBA Observed Finance Wellbeing Scale and tested against multiple datasets to validate output was correct </li> <li> Created gauge chart using python to visualise the years remaining on a home loan (displayed loan total years, years passed and years remaining) </li> <li> Created a sankey chart using python to visualise the spread of total spend across the mid level transaction classification heirachy </li> <li> Held weekly meetings for DS/AI stream, created group posts of key dates for end of trimester, created new trello cards for visualisations and financial wellbeing tasks, assisted students with clarifying tasks, providing feedback on submissions </li> 
| Sri Harsha Vardhan | <li> Improved the previous BERT model with adding more epochs, dividing the input dataset into batches and also using attention masks on a new dataset to improve the accuracy of the model to 79%. </li> <li> Also written code to save the best performing model, so that this model could be called upon to generate sentiment for a feedback text in the feedback form API. </li> <li> Used mockaroo to generate fake feedback form data to generate graphs for the dashboard from this data. </li> <li> Modified the visualization code for the feedback dashboard to also accept html files and not just the image files for the pie charts. This enabled me to fix the Sankey diagram error and display it in the frontend for the data generated as mentioned above. </li> <li> Added code to the feedback API in the backend to store the data in a database table instead of a csv file and also added the function to call the sentiment analysis model generated by the BERT model, so that the review and it’s sentiment can be stored at the same time. This is not yet enabled as changes are being made to the database. </li> <li> Also added sentiment analysis from textblob as a fallback because the 411MB model generated from the training couldn’t be pushed to github without complicating the repo by adding github large file storage. </li> <li> Analysed all the savings prediction models and used the best performing random forest model to create a simplified version of it and pushed it to github. </li> <li> Made changes in the frontend HTML files like the header and footer section, so that they contain the buttons for feedback dashboard and feedback form. </li> <li> Also added wordclouds to the feedback dashboard for the review text from feedback form. </li> 
| Gimsara Kenula Elgiriyage | <li>Met with the Product Owner and mentor weekly to update and discuss the product and tasks.</li><li>Created new Trello cards for Front End stream.</li><li>Assigned tasks to FE team members.</li><li>Hosted meetings with the Front-End stream (group and individual meetings) to provide clarity on tasks and help peers.</li><li>Started upskilling on React.</li><li>Figured out the problem with the article routes were BE related, hence notified the BE leader, Junkai to setup a trello card in the BE stream to fix this issue.</li><li>No one in the FE team volunteered to become a coleader, so had to take on in managing the large FE team.</li><li>Appointed two leads, Krish and Divanshi, to lead the sub group on the transition to React.</li><li>Reviewed and merged the two commits from FE members on developing the reset password and register pages.</li><li>Worked on improving a half built survey by Junkai, by adding new questions to it and rephrasing some of the existing questions. Then integrated it onto our webapp. Added it to the dashboard page.</li><li>Met with Denica, the DS/AI stream leader, and discussed the updates that need to be in the dashboard.</li><li>Reviewed and merged the feature to delete a user account to the develop branch developed by a FE member.</li><li>The task on developing a feature for the user to leave a review was handed over to Saad Ali as he was looking for a task.</li><li>Successfully completed developing an in-app notification system.</li><li>Updated the BE leader that this task needs a corresponding BE task.</li><li>Updated the dashboard by removing the title drop shadow, which was going out of the screen size, removing the three pie charts with dummy data and the two line graphs at the bottom of the page.</li><li>Assigned the visualisation task to Gunjan Sharma and Sushant Dudeja. Gunjan was given the transaction data to be visualised and Sushant was given the home loan data to be visualised (2 graphs each).</li><li>Reviewed and merged the work of the transition to React.</li><li>Met with the Dolfin Leadership team to discuss and decide on the final responsibilities, the handover documents, and the upcoming deadlines.</li>|
</details>
